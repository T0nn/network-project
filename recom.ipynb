{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS120 Mini-project on Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your submissions of ratings over a wide range of movies, we selected the ratings from 22 students over 266 movies. We then constructed a rating matrix with dimension ($266 \\times 22$), with its $(i,j)$th entry referring to the rating of user $j$ over movie $i$. Now $33$ entries with ratings in the matrix are missing; each of them is replaced with $-1$. \n",
    "\n",
    "Your assignment is to try different (at least one, but surely one might be inadequate) methods that we've introduced in the class, to recover (or you can imagine that those missing entries are what we try to figure out) those missing entries. \n",
    "\n",
    "- You need to illustrate the methods that you adopt in detail, including parameter settings and the reasoning of your choice. \n",
    "- Next, you need to write your code in the required box, and run them with output and write to files. \n",
    "- Besides, code annotation is also necessary. Too simple answer or annotation **receives no grade**.\n",
    "- At last, you should compare different methods that you adopt (in terms of performance, for instance) and show your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset that you have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, more than the corrupted rating matrix, we also provide you with the names of movies (see *Movie-list* file in the foler *Basic-dataset*). The hint is that you could also think about making use of the correlation between different movies. For example, different movies may belong to similar genre(s) (or with the same actresses/actors). \n",
    "\n",
    "The above is just one possible way. At the same time, you may find another foler *Other-avaliable-dataset*. That is a much larger dataset with users' ratings over even more movies (from real-world, too). You can also make use of information there, e.g. see more people's rating over the same movie in our basic dataset; in other words, you can regard it as a potential / optional training set, although we don't require you to import it). \n",
    "\n",
    "Remember: we need the recovered matrix. Others are optional. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the method(s) here (at least one), which you adopt in your mini project to recover the missing pieces in the rating matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I just use the baseline model to get my hands dirty and get familiar with ipython notebook and numpy, as I use matlab in my previous homework. So the implementation of baseline predictor is not very hard, and we don't need involve any parameter. What we do is to minimize $\\|Ab-c\\|$, so I just calculate $A$ and $c$, and $b=A^{\\dagger}c$ to finally get recover rating matrix. \n",
    "\n",
    "To take control of overfitting, I modified the baseline predictor with  regularization, which is $min \\{\\|Ab-c\\| +  \\|\\lambda\\|\\}$. First, I just set lamda to 1, which generate better result compared with simple baseline model. However, to find the optimal lamda, I tried to use the cross validation techniques. Since I don't have enough time to fully understand the technique to select the optimal lamda, such as Leave-one-out computations, I just use ***sklearn*** module to obtain the lamda, which has already implemented cross validation to tunne the parameter.\n",
    "\n",
    "Once I finished the baseline predictor, I try to use the neighborhood model to get more accurate prediction. And I use the movie-movie correlation.\n",
    "\n",
    "---\n",
    "Note: for convenience, I use the rating_matrix_to_rec.transpose() $\\left(22 \\times 266\\right)$ in most part of my code, however, save the recover matrix in rating_matrix_to_rec form ($266 \\times 22$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then for each method, fill up with your runnable code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: baseline model with regularization\n",
      "Estimated training set: [ 4.57596321  4.83545335  1.          1.          4.1800691   4.22231713\n",
      "  3.90904872  4.          5.          4.10193859  5.          3.57145138\n",
      "  2.34714067  3.60329957  4.15331828  3.94838543  4.37179886  3.          4.\n",
      "  4.48732995  2.          2.39791359  3.94794489  4.12240267  3.67823673\n",
      "  1.5         4.5         2.          4.87839051  1.66759739  3.2         4.8\n",
      "  2.          3.4         2.96965764  1.97341152  2.81770747  1.8\n",
      "  3.7680086   2.88038695  4.5         4.8         4.7         4.6         4.9\n",
      "  4.08517303  4.7         4.7056548   1.          2.5         4.\n",
      "  3.43753902  2.79608152  4.          4.72799514  3.11048277  2.          3.5\n",
      "  3.6247567   4.23667415  3.70618694  3.          3.73803513  3.5\n",
      "  4.28805384  3.8341948   1.5         1.92608147  3.          4.64783707\n",
      "  4.          4.5         3.          4.5         3.5         3.5         4.\n",
      "  4.5         2.          3.5         1.92608147  3.          2.          5.\n",
      "  3.          4.          4.          1.          2.          2.19906917\n",
      "  5.          2.          4.43248647  5.          4.          3.\n",
      "  4.18473172  4.          5.          3.23053629  5.13469272  3.81848363\n",
      "  4.97412553  3.          3.80798151  2.          1.          2.83034236\n",
      "  5.          4.33001252  4.5         4.06751353  4.0477209   4.29199046\n",
      "  4.76971979  4.41144937  4.04684623  4.52424799  2.5         3.39804983\n",
      "  4.1494869   4.62721623  0.96127648  5.          2.          5.          4.\n",
      "  5.          5.          4.          5.          5.          1.          5.\n",
      "  2.          4.          1.          4.2620204   5.70213121  4.85767785\n",
      "  3.          5.          2.          4.16948132  1.          4.          5.2943452\n",
      "  4.          4.          2.          5.01999614  5.          4.77485191\n",
      "  4.18151637  4.18448814  2.          3.          5.          4.5         2.\n",
      "  3.88102373  3.          4.          4.5         1.93448814  5.          4.5\n",
      "  4.          1.5         4.          5.          2.          3.82021964\n",
      "  3.          4.33678782  4.34225065  4.2528489   3.72236169  2.          3.\n",
      "  5.          5.          4.32681129  4.78195792  1.          3.\n",
      "  4.41676209  1.          4.63132894  3.8         4.23543483  3.84020615\n",
      "  4.27768287  4.24124324  3.6586653   3.          4.20868402  4.68641334\n",
      "  3.          3.2991238   4.5         4.5         5.          4.32121751\n",
      "  4.9         4.8         5.          3.70391848  5.22845004  5.55768275\n",
      "  3.58229253  4.01831973  4.7         4.3         4.9         4.2         4.1\n",
      "  3.76946371  4.75        5.19589081  4.30195017  4.74203177  4.38256297\n",
      "  2.8         4.41338013  2.3         3.59144018  2.1         4.39985934\n",
      "  3.05205511  3.22651289  4.7         4.22459782  3.90853835  3.2\n",
      "  2.49947918  4.3         4.43969636  1.5         3.98250073  4.07937695\n",
      "  4.12739648  2.          3.          5.          4.74317687  4.\n",
      "  4.72965608  3.55630963  4.32773683  2.          3.70459473  4.94358332\n",
      "  4.          4.31229747  1.10150436  4.40917369  4.04457054  4.56266038\n",
      "  3.71820702  4.          3.          2.          5.          1.          4.3339874\n",
      "  2.65219882  1.          3.81551186  5.          1.56551186  4.24231725\n",
      "  3.81851542  3.29540527  3.          4.36030364  4.          3.63538108\n",
      "  4.71014488  5.          4.          1.          4.31425077  4.\n",
      "  1.82960573  5.          5.          4.04323039  2.          5.          1.\n",
      "  5.          3.81526828  5.          5.          4.28749995  4.\n",
      "  4.92562954  1.          4.69695657  3.01516799  3.39297966  4.2702453\n",
      "  4.18148458  1.          4.          4.          4.50817426  3.23648132\n",
      "  1.          4.24349448  1.05528406  3.99835024  4.47575201  3.          5.\n",
      "  1.07391853  4.84248945  3.669143    4.          1.          4.66722793\n",
      "  5.05641668  5.          1.07391853  3.          4.40254815  3.\n",
      "  1.21433772  5.          3.55161457  4.29671865  2.          1.\n",
      "  4.91249903  3.85216293  2.          5.          5.          3.7256318   4.\n",
      "  5.          3.          2.65285933  3.          2.          5.\n",
      "  4.45903695  3.54947673  1.          2.83263319  4.09351891  2.5\n",
      "  3.71482697  2.60052082  3.15139947  3.60710064  4.59296077  5.          5.1072347\n",
      "  4.21961305  4.76351868  3.          5.3166728 ]\n",
      "RMSE over training set: 0.460267068446\n",
      "Estimated test set: [ 3.23216595  4.59325958  3.93465548  3.93465548  3.51015341  4.52031137\n",
      "  4.33355874  5.90857962  4.33355874  4.12967217  4.00227568  4.86198695\n",
      "  4.09884381  4.09884381  4.09884381  3.45903646  3.32834925  4.79046464\n",
      "  3.32834925  3.32834925  3.32834925  3.28753168  4.41669355  1.02047359\n",
      "  4.27473848  3.0387657   3.36856244  3.36634762  3.36634762  3.32234214\n",
      "  3.32234214  3.48139581  3.20953536]\n",
      "RMSE over test set: 1.29838157966\n"
     ]
    }
   ],
   "source": [
    "#Method 1\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "rating_matrix_to_rec = []\n",
    "\n",
    "## Import the rating matrix to recover here\n",
    "## as a [[..], [..], .., [..]] data structure.\n",
    "with open('Basic-dataset/rating_matrix_to_rec.csv', 'r') as f:\n",
    "    reader  = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        row = list(map(lambda val: float(val), row))\n",
    "        rating_matrix_to_rec.append(row)\n",
    "        \n",
    "num_of_users = len(rating_matrix_to_rec[0])\n",
    "num_of_movies= len(rating_matrix_to_rec)\n",
    "\n",
    "rating_matrix = np.array(rating_matrix_to_rec)\n",
    "matrix_rec    = np.zeros((num_of_users, num_of_movies)) \n",
    "\n",
    "rating_matrix_to_rec = []\n",
    "## import the testing matrix to calculate RMSE\n",
    "with open('Basic-dataset/ratings.csv', 'r') as f:\n",
    "    reader  = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        row = list(map(lambda val: float(val), row))\n",
    "        rating_matrix_to_rec.append(row)\n",
    "        \n",
    "test_rating_matrix = np.array(rating_matrix_to_rec).transpose()\n",
    "        \n",
    "## Now you may start here..\n",
    "\n",
    "# count rated movies number and average rating\n",
    "rating_number = (rating_matrix>0).sum()\n",
    "rating_average = rating_matrix.sum()/rating_number\n",
    "\n",
    "# build vector c\n",
    "c = rating_matrix.ravel()[rating_matrix.ravel()>0] - rating_average\n",
    "\n",
    "rating_matrix = rating_matrix.transpose()\n",
    "\n",
    "# build matrix A\n",
    "A = np.zeros((rating_number ,num_of_users+num_of_movies))\n",
    "\n",
    "count = 0\n",
    "for j in range(0, len(rating_matrix[0])):\n",
    "    for i in range (0, len(rating_matrix)):\n",
    "        if (rating_matrix[i][j]>0):\n",
    "            A[count, i]=1\n",
    "            A[count,num_of_users+j]=1\n",
    "            count+=1\n",
    "\n",
    "# calculate b\n",
    "b = np.dot(np.linalg.pinv(A), c)\n",
    "\n",
    "bu = b[0:num_of_users]\n",
    "bi = b[num_of_users:].transpose();\n",
    "\n",
    "bus = np.tile(bu.transpose(), (num_of_movies,1)).transpose()\n",
    "bis = np.tile(bi, (num_of_users,1))\n",
    "\n",
    "# use b's introduced bu's and bi's to recover matrix\n",
    "matrix_baseline = bus+bis\n",
    "matrix_baseline += rating_average\n",
    "matrix_baseline[matrix_baseline>5] = 5\n",
    "matrix_baseline[matrix_baseline<1] = 1\n",
    "\n",
    "matrix_rec = matrix_baseline\n",
    "\n",
    "## Ends up with the variable named 'matrix_rec' that you recover.\n",
    "\n",
    "## results of the RMSE with correspondant results\n",
    "print('Method:', 'baseline model with regularization')\n",
    "\n",
    "print('Estimated training set:', matrix_rec[rating_matrix>0])\n",
    "\n",
    "# calculate RMSE of training\n",
    "RMSE_of_trn_set = np.sqrt(((matrix_rec[rating_matrix>0]-rating_matrix[rating_matrix>0])**2/rating_number).sum())\n",
    "print('RMSE over training set:', RMSE_of_trn_set)\n",
    "\n",
    "print('Estimated test set:', matrix_rec[rating_matrix==-1])\n",
    "\n",
    "# calculate RMSE of testing data\n",
    "RMSE_of_tst_set = np.sqrt(((matrix_rec[rating_matrix==-1]-test_rating_matrix[rating_matrix==-1])**2/(rating_matrix==-1).sum()).sum())\n",
    "print('RMSE over test set:', RMSE_of_tst_set)\n",
    "\n",
    "### Write output to file\n",
    "your_name_in_English = 'xiegsh'\n",
    "your_student_id = '97382505'\n",
    "\n",
    "with open(your_name_in_English + '_' + your_student_id + '_rec_matrix_1.csv', 'w+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(matrix_rec.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: baseline model with regularization\n",
      "Estimated training set: [ 4.27933852  4.73210785  2.22269159  2.22269159  4.01322366  3.90035945\n",
      "  3.77435798  3.72269159  4.22269159  4.05729641  4.22269159  3.64630379\n",
      "  2.83122567  3.58269413  4.19746565  3.77713645  3.97995423  3.30712468\n",
      "  3.80712468  3.95670963  2.80712468  2.35892316  3.66146081  3.79273638\n",
      "  3.54237401  2.55712468  4.05712468  2.80712468  4.34947033  1.69745183\n",
      "  3.4412469   4.2412469   2.8412469   3.5412469   3.22576859  2.4271676\n",
      "  3.1319314   2.7412469   3.94288685  3.33491289  4.0912469   4.2412469\n",
      "  4.1912469   4.1412469   4.2912469   3.97367409  4.1912469   4.50066317\n",
      "  2.15784252  2.90784252  3.65784252  3.45234161  2.92072556  3.65784252\n",
      "  4.3490002   3.2438097   2.65784252  3.40784252  3.5760781   3.92759827\n",
      "  3.51660565  3.15784252  3.45299598  3.40784252  4.06776751  3.73786651\n",
      "  2.4825161   2.16224056  3.2325161   4.01099168  3.7325161   3.9825161\n",
      "  3.2325161   3.9825161   3.4825161   3.4825161   3.7325161   3.9825161\n",
      "  2.7325161   3.4825161   2.16224056  3.2325161   2.81442602  4.31442602\n",
      "  3.31442602  3.81442602  3.81442602  2.31442602  2.81442602  2.37352584\n",
      "  4.31442602  2.81442602  4.09000741  4.31442602  3.81442602  3.31442602\n",
      "  3.83555609  3.81442602  4.31442602  3.29617022  4.6489031   3.79823533\n",
      "  4.7744065   3.24384092  3.8533867   2.74384092  2.24384092  3.03095662\n",
      "  4.24384092  4.12437901  3.99384092  3.94883721  3.81665663  4.2397643\n",
      "  4.5077329   4.14716227  4.01025701  4.23355769  2.99384092  3.43539009\n",
      "  4.39030482  4.65827342  1.72142482  4.31911118  2.81911118  4.31911118\n",
      "  3.81911118  4.31911118  4.31911118  3.81911118  4.31911118  4.31911118\n",
      "  2.31911118  4.31911118  2.81911118  3.81911118  2.31911118  4.19743242\n",
      "  5.          4.4631449   3.43149904  4.43149904  2.93149904  3.99965464\n",
      "  2.43149904  3.93149904  4.68116745  3.93149904  3.93149904  2.93149904\n",
      "  4.61508054  4.43149904  4.38557325  4.03238137  3.9567972   2.76982248\n",
      "  3.26982248  4.26982248  4.01982248  2.76982248  3.88210522  3.26982248\n",
      "  3.76982248  4.01982248  2.4567972   4.26982248  4.01982248  3.76982248\n",
      "  2.51982248  3.71762467  4.21762467  2.71762467  3.80095421  3.21762467\n",
      "  4.06763013  4.07194652  4.04716257  3.63616995  2.71762467  3.21762467\n",
      "  4.21762467  4.21762467  4.17047032  4.45530041  2.21762467  3.21762467\n",
      "  3.99445942  2.21762467  4.52364336  3.74484401  4.25752849  4.03214829\n",
      "  4.14466428  4.32206881  3.82699896  3.34484401  4.44177049  4.70973909\n",
      "  3.34484401  3.60700235  4.09484401  4.09484401  4.34484401  4.24889809\n",
      "  4.6345967   4.5845967   4.6845967   3.97423392  5.          5.          3.818631\n",
      "  4.29731805  4.5345967   4.3345967   4.6345967   4.2845967   4.2345967\n",
      "  4.03651159  4.5595967   5.          4.31690165  4.79137486  4.07807164\n",
      "  3.02205815  4.31827052  2.77205815  3.58657658  2.67205815  4.27743146\n",
      "  3.29132775  3.42260332  3.97205815  4.10357889  3.85602953  3.22205815\n",
      "  2.78142243  3.77205815  4.02644477  2.37205815  3.97933728  3.90359674\n",
      "  4.13042696  2.76514006  3.26514006  4.26514006  4.60443434  3.76514006\n",
      "  4.56359529  3.70876715  4.1669773   2.76514006  3.61722065  4.53907251\n",
      "  3.76514006  4.2655011   1.6134826   4.18976056  4.0528553   4.49562297\n",
      "  3.80904513  3.60444915  3.10444915  2.60444915  4.10444915  2.10444915\n",
      "  4.28305252  2.90200975  2.10444915  3.62605055  4.10444915  2.12605055\n",
      "  3.9495344   3.71436866  3.29583883  3.10444915  3.99122677  3.60444915\n",
      "  3.73147348  4.58499114  4.3755179   3.8755179   2.3755179   4.31887628\n",
      "  3.8755179   2.4957096   4.3755179   4.3755179   4.0800106   2.8755179\n",
      "  4.3755179   2.3755179   4.3755179   3.95773986  4.3755179   4.3755179\n",
      "  4.50311827  3.8755179   4.56141528  2.13734531  4.34884483  2.96780206\n",
      "  3.41134718  3.84253109  3.78016098  2.13734531  3.63734531  3.63734531\n",
      "  4.1341532   3.3630441   2.13734531  4.02677308  1.35789308  3.79726579\n",
      "  4.02056646  3.22167137  4.22167137  2.14055109  4.47665789  3.62182975\n",
      "  3.72167137  2.22167137  4.30280532  4.45213511  4.22167137  2.14055109\n",
      "  3.22167137  4.1954252   3.22167137  1.5265452   4.22167137  3.55997645\n",
      "  3.99723619  2.69854468  2.19854468  4.47124357  3.94304884  2.69854468\n",
      "  4.19854468  4.19854468  3.57557638  3.69854468  4.19854468  3.19854468\n",
      "  2.78293184  3.19854468  2.69854468  4.19854468  4.14917182  3.31440369\n",
      "  2.19854468  2.93707675  3.8763461   2.87198266  3.53514561  2.78127144\n",
      "  3.16127964  3.66614678  4.38837359  4.73012447  4.72064199  4.11266802\n",
      "  4.54860242  3.73012447  4.8824304 ]\n",
      "RMSE over training set: 0.68863601751\n",
      "Estimated test set: [ 3.44538319  4.47869835  3.61424936  3.61424936  3.6824938   4.06156089\n",
      "  3.4650322   4.47382458  3.4650322   4.08782866  3.72254177  4.26270445\n",
      "  3.86299807  3.86299807  3.86299807  3.49101542  3.53964495  4.34110027\n",
      "  3.53964495  3.53964495  3.53964495  3.68968802  4.1958471   1.77289049\n",
      "  4.3691934   3.24411631  3.53028013  3.7510358   3.7510358   3.27469062\n",
      "  3.27469062  3.44334273  3.12726688]\n",
      "RMSE over test set: 1.23256350735\n"
     ]
    }
   ],
   "source": [
    "#Method 2\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "rating_matrix_to_rec = []\n",
    "\n",
    "## Import the rating matrix to recover here\n",
    "## as a [[..], [..], .., [..]] data structure.\n",
    "with open('Basic-dataset/rating_matrix_to_rec.csv', 'r') as f:\n",
    "    reader  = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        row = list(map(lambda val: float(val), row))\n",
    "        rating_matrix_to_rec.append(row)\n",
    "        \n",
    "num_of_users = len(rating_matrix_to_rec[0])\n",
    "num_of_movies= len(rating_matrix_to_rec)\n",
    "\n",
    "rating_matrix = np.array(rating_matrix_to_rec)\n",
    "matrix_rec    = np.zeros((num_of_users, num_of_movies)) \n",
    "\n",
    "rating_matrix_to_rec = []\n",
    "## import the testing matrix to calculate RMSE\n",
    "with open('Basic-dataset/ratings.csv', 'r') as f:\n",
    "    reader  = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        row = list(map(lambda val: float(val), row))\n",
    "        rating_matrix_to_rec.append(row)\n",
    "        \n",
    "test_rating_matrix = np.array(rating_matrix_to_rec).transpose()\n",
    "        \n",
    "## Now you may start here..\n",
    "\n",
    "# count rated movies number and average rating\n",
    "rating_number = (rating_matrix>0).sum()\n",
    "rating_average = rating_matrix.sum()/rating_number\n",
    "\n",
    "# build vector c\n",
    "c = rating_matrix.ravel()[rating_matrix.ravel()>0] - rating_average\n",
    "\n",
    "rating_matrix = rating_matrix.transpose()\n",
    "\n",
    "# build matrix A\n",
    "A = np.zeros((rating_number ,num_of_users+num_of_movies))\n",
    "\n",
    "count = 0\n",
    "for j in range(0, len(rating_matrix[0])):\n",
    "    for i in range (0, len(rating_matrix)):\n",
    "        if (rating_matrix[i][j]>0):\n",
    "            A[count, i]=1\n",
    "            A[count,num_of_users+j]=1\n",
    "            count+=1\n",
    "            \n",
    "# get optimal parameter lamda\n",
    "# try to import sklearn module\n",
    "try:\n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.RidgeCV(alphas=[1+0.0001*i for i in range(1,10000)])\n",
    "    reg.fit(A,c)\n",
    "    lamda = reg.alpha_\n",
    "# else using pre-calculated value\n",
    "except ImportError:\n",
    "    lamda = 1.63018\n",
    "\n",
    "# calculate b\n",
    "b = np.dot(np.linalg.pinv( np.dot(A.transpose(), A) + lamda * np.eye( A.shape[1] ) ), np.dot(A.transpose(), c))\n",
    "\n",
    "bu = b[0:num_of_users]\n",
    "bi = b[num_of_users:].transpose();\n",
    "\n",
    "bus = np.tile(bu.transpose(), (num_of_movies,1)).transpose()\n",
    "bis = np.tile(bi, (num_of_users,1))\n",
    "\n",
    "# use b's introduced bu's and bi's to recover matrix\n",
    "matrix_baseline = bus+bis\n",
    "matrix_baseline += rating_average\n",
    "matrix_baseline[matrix_baseline>5] = 5\n",
    "matrix_baseline[matrix_baseline<1] = 1\n",
    "\n",
    "matrix_rec = matrix_baseline\n",
    "\n",
    "## Ends up with the variable named 'matrix_rec' that you recover.\n",
    "\n",
    "## results of the RMSE with correspondant results\n",
    "print('Method:', 'baseline model with regularization')\n",
    "\n",
    "print('Estimated training set:', matrix_rec[rating_matrix>0])\n",
    "\n",
    "# calculate RMSE of training\n",
    "RMSE_of_trn_set = np.sqrt(((matrix_rec[rating_matrix>0]-rating_matrix[rating_matrix>0])**2/rating_number).sum())\n",
    "print('RMSE over training set:', RMSE_of_trn_set)\n",
    "\n",
    "print('Estimated test set:', matrix_rec[rating_matrix==-1])\n",
    "\n",
    "# calculate RMSE of testing data\n",
    "RMSE_of_tst_set = np.sqrt(((matrix_rec[rating_matrix==-1]-test_rating_matrix[rating_matrix==-1])**2/(rating_matrix==-1).sum()).sum())\n",
    "print('RMSE over test set:', RMSE_of_tst_set)\n",
    "\n",
    "### Write output to file\n",
    "your_name_in_English = 'xiegsh'\n",
    "your_student_id = '97382505'\n",
    "\n",
    "with open(your_name_in_English + '_' + your_student_id + '_rec_matrix_1.csv', 'w+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(matrix_rec.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: neighborhood model\n",
      "Estimated training set: [ 4.57596321  4.83545335  1.          1.          4.1800691   4.22231713\n",
      "  3.90904872  4.          5.          4.86525886  5.          3.3650862\n",
      "  2.34714067  3.86526444  4.86526444  3.94838543  4.37179886  3.          4.\n",
      "  5.          2.          2.39791359  3.39588977  5.          3.67823673\n",
      "  1.5         4.5         2.          4.3297425   1.76910174  3.2         4.8\n",
      "  2.          3.4         2.96965764  1.97341152  2.81770747  1.8\n",
      "  3.7680086   3.1         4.5         4.8         4.7         4.6         4.9\n",
      "  4.08517303  4.7         4.7056548   1.          2.5         4.\n",
      "  3.43753902  2.79608152  4.          4.72799514  2.70344353  2.          3.5\n",
      "  3.6247567   4.23667415  3.70618694  3.          3.39670043  3.5\n",
      "  4.49673786  3.8341948   1.5         2.          3.          4.64783707\n",
      "  4.          4.5         3.          4.5         3.5         3.5         4.\n",
      "  4.5         2.          3.5         2.          3.          2.          5.\n",
      "  3.          4.          4.          1.          2.          3.0286749   5.\n",
      "  2.          5.          5.          4.          3.          5.          4.\n",
      "  5.          3.23053629  5.          3.81848363  4.97412553  3.\n",
      "  3.80798151  2.          1.          2.83034236  5.          4.33001252\n",
      "  4.5         4.06751353  5.          3.322907    5.          4.41144937\n",
      "  4.04684623  4.52424799  2.5         3.39804983  3.94080288  4.42995838\n",
      "  1.          5.          2.          5.          4.          5.          5.\n",
      "  4.          5.          5.          1.          5.          2.          4.\n",
      "  1.          3.85096427  4.73862663  4.57588487  3.          5.          2.\n",
      "  5.          1.          4.          5.          4.          4.          2.\n",
      "  5.          5.          5.          4.18151637  5.          2.          3.\n",
      "  5.          4.5         2.          3.88102373  3.          4.          4.5\n",
      "  1.5         5.          4.5         4.          1.5         4.          5.\n",
      "  2.          3.82021964  3.          4.33678782  4.34225065  5.\n",
      "  4.65091031  2.          3.          5.          5.          4.32681129\n",
      "  4.40917415  1.          3.          4.67878249  1.          4.63132894\n",
      "  3.8         4.23543483  3.84020615  4.27768287  4.64772433  3.39670043\n",
      "  3.          3.49673786  4.68641334  3.          3.14772433  4.5         4.5\n",
      "  5.          4.32121751  4.9         4.8         5.          3.70391848\n",
      "  4.95875676  5.          3.58229253  4.01831973  4.7         4.3         4.9\n",
      "  4.2         4.1         3.76946371  4.75        4.74136171  4.40390035\n",
      "  4.74203177  4.38256297  2.8         4.74736753  2.3         3.60411023\n",
      "  2.1         4.39985934  3.60411023  3.60411023  4.7         4.22459782\n",
      "  3.90853835  3.2         2.49947918  4.3         3.8         1.5\n",
      "  4.10411023  4.07937695  4.12739648  2.          3.          5.\n",
      "  4.74317687  4.          4.88716663  2.93625772  4.32773683  2.\n",
      "  3.70459473  4.94358332  4.          4.19068798  1.03566876  4.40917369\n",
      "  4.04457054  4.56266038  3.71852027  4.          3.          2.          5.\n",
      "  1.          4.07716427  2.65219882  1.          3.81551186  5.\n",
      "  1.56551186  4.24231725  3.81851542  3.          3.          4.36030364\n",
      "  4.          3.55286839  5.          5.          4.          1.\n",
      "  4.49431987  4.          1.82960573  5.          5.          4.8211584   2.\n",
      "  5.          1.          5.          3.81526828  5.          5.\n",
      "  3.51683603  4.          4.92562954  1.          4.69695657  3.01516799\n",
      "  4.22349834  4.2702453   4.18148458  1.          4.          4.\n",
      "  4.84094633  3.23648132  1.          4.27566043  1.          4.22349834\n",
      "  4.47575201  3.          5.          1.07391853  4.11283337  3.17121702\n",
      "  4.          1.          4.66722793  5.          5.          1.07391853\n",
      "  3.          4.40254815  3.          1.36409177  5.          3.55161457\n",
      "  4.01492567  2.          1.          5.          3.85216293  2.          5.\n",
      "  5.          3.7256318   4.          5.          3.          2.30571866\n",
      "  3.          2.          5.          5.          3.54947673  1.\n",
      "  2.83263319  4.72223512  2.5         3.71482697  2.60052082  2.85227567\n",
      "  3.8491324   4.70344353  5.          5.          4.          4.76351868\n",
      "  3.          4.3341948 ]\n",
      "RMSE over training set: 0.45304426716\n",
      "Estimated test set: [ 3.23216595  4.86526444  3.93465548  3.93465548  3.51015341  4.52031137\n",
      "  4.33355874  5.          4.33355874  4.12967217  4.00227568  4.86198695\n",
      "  4.09884381  4.09884381  4.09884381  3.45903646  3.32834925  4.79046464\n",
      "  3.32834925  3.32834925  3.32834925  3.28753168  4.41669355  1.02047359\n",
      "  4.27473848  3.0387657   3.36856244  3.36634762  3.36634762  3.32234214\n",
      "  3.32234214  3.48139581  3.20953536]\n",
      "RMSE over test set: 1.28697937343\n"
     ]
    }
   ],
   "source": [
    "#Method 3\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "rating_matrix_to_rec = []\n",
    "\n",
    "## Import the rating matrix to recover here\n",
    "## as a [[..], [..], .., [..]] data structure.\n",
    "with open('Basic-dataset/rating_matrix_to_rec.csv', 'r') as f:\n",
    "    reader  = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        row = list(map(lambda val: float(val), row))\n",
    "        rating_matrix_to_rec.append(row)\n",
    "        \n",
    "num_of_users = len(rating_matrix_to_rec[0])\n",
    "num_of_movies= len(rating_matrix_to_rec)\n",
    "\n",
    "rating_matrix = np.array(rating_matrix_to_rec)\n",
    "matrix_rec    = np.zeros((num_of_users, num_of_movies)) \n",
    "\n",
    "rating_matrix_to_rec = []\n",
    "## import the testing matrix to calculate RMSE\n",
    "with open('Basic-dataset/ratings.csv', 'r') as f:\n",
    "    reader  = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        row = list(map(lambda val: float(val), row))\n",
    "        rating_matrix_to_rec.append(row)\n",
    "        \n",
    "test_rating_matrix = np.array(rating_matrix_to_rec).transpose()\n",
    "        \n",
    "## Now you may start here..\n",
    "\n",
    "# count rated movies number and average rating\n",
    "rating_number = (rating_matrix>0).sum()\n",
    "rating_average = rating_matrix.sum()/rating_number\n",
    "\n",
    "# build vector c\n",
    "c = rating_matrix.ravel()[rating_matrix.ravel()>0] - rating_average\n",
    "\n",
    "rating_matrix = rating_matrix.transpose()\n",
    "\n",
    "# build matrix A\n",
    "A = np.zeros((rating_number ,num_of_users+num_of_movies))\n",
    "\n",
    "count = 0\n",
    "for j in range(0, len(rating_matrix[0])):\n",
    "    for i in range (0, len(rating_matrix)):\n",
    "        if (rating_matrix[i][j]>0):\n",
    "            A[count, i]=1\n",
    "            A[count,num_of_users+j]=1\n",
    "            count+=1\n",
    "\n",
    "# calculate b\n",
    "b = np.dot(np.linalg.pinv(A), c)\n",
    "\n",
    "bu = b[0:num_of_users]\n",
    "bi = b[num_of_users:].transpose();\n",
    "\n",
    "bus = np.tile(bu.transpose(), (num_of_movies,1)).transpose()\n",
    "bis = np.tile(bi, (num_of_users,1))\n",
    "\n",
    "# use b's introduced bu's and bi's to recover matrix\n",
    "matrix_baseline = bus+bis\n",
    "matrix_baseline += rating_average\n",
    "matrix_baseline[matrix_baseline>5] = 5\n",
    "matrix_baseline[matrix_baseline<1] = 1\n",
    "\n",
    "matrix_rec = matrix_baseline\n",
    "\n",
    "# continue to build neighborhood modle\n",
    "\n",
    "# build matrix_tilde\n",
    "matrix_tilde = rating_matrix-matrix_baseline\n",
    "matrix_tilde[rating_matrix<=0] = 0\n",
    "\n",
    "# build matrix D\n",
    "D = np.zeros((num_of_users,num_of_users))\n",
    "for i in range(num_of_users):\n",
    "    for j in range(num_of_users):\n",
    "        index = np.logical_and((rating_matrix[i,:]>0), (rating_matrix[j,:]>0))\n",
    "        ri = matrix_tilde[i, index]\n",
    "        rj = matrix_tilde[j, index]\n",
    "        if ri.size>1:\n",
    "            D[i,j] =np.dot(ri,rj) / np.sqrt(np.dot(ri,ri) * np.dot(rj,rj))\n",
    "        else:\n",
    "            D[i,j]=np.nan\n",
    "# wipe off self\n",
    "D[np.eye(num_of_users)>0]=np.nan\n",
    "\n",
    "# build neighborhood matrix\n",
    "matrix_neighborhood = np.zeros((num_of_users,num_of_movies))\n",
    "# select most 2 close neighbor\n",
    "k=2\n",
    "for j in range(num_of_users):\n",
    "    index = np.argsort(np.abs(D[j,:]), axis=None)[0:k]\n",
    "    for i in range(num_of_movies):\n",
    "        index_tmp = index\n",
    "        index_tmp = index_tmp[rating_matrix[index_tmp,i]>0]\n",
    "        if index_tmp.size > 0:\n",
    "            tmp = np.abs(D[index_tmp,j]).sum()\n",
    "            if tmp*(tmp==tmp)>0:\n",
    "                matrix_neighborhood[j,i] = np.dot(D[index_tmp,j], matrix_tilde[index_tmp,i])/tmp\n",
    "\n",
    "matrix_rec = matrix_baseline+matrix_neighborhood\n",
    "matrix_rec[matrix_rec>5] = 5\n",
    "matrix_rec[matrix_rec<1] = 1\n",
    "\n",
    "## Ends up with the variable named 'matrix_rec' that you recover.\n",
    "\n",
    "## results of the RMSE with correspondant results\n",
    "print('Method:', 'neighborhood model')\n",
    "\n",
    "print('Estimated training set:', matrix_rec[rating_matrix>0])\n",
    "\n",
    "# calculate RMSE of training\n",
    "RMSE_of_trn_set = np.sqrt(((matrix_rec[rating_matrix>0]-rating_matrix[rating_matrix>0])**2/rating_number).sum())\n",
    "print('RMSE over training set:', RMSE_of_trn_set)\n",
    "\n",
    "print('Estimated test set:', matrix_rec[rating_matrix==-1])\n",
    "\n",
    "# calculate RMSE of testing data\n",
    "RMSE_of_tst_set = np.sqrt(((matrix_rec[rating_matrix==-1]-test_rating_matrix[rating_matrix==-1])**2/(rating_matrix==-1).sum()).sum())\n",
    "print('RMSE over test set:', RMSE_of_tst_set)\n",
    "\n",
    "### Write output to file\n",
    "your_name_in_English = 'xiegsh'\n",
    "your_student_id = '97382505'\n",
    "\n",
    "with open(your_name_in_English + '_' + your_student_id + '_rec_matrix_1.csv', 'w+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(matrix_rec.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison and your analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1\n",
    "As we can see, the fitting accuracy of baseline model is very well for training data. which usually result in overfitting according to noise. So the RMSE over training set is highly optimal $0.454441117893$, and the RMSE over test set: $1.28871217194$. So we can introduce regulation to take control of the hindsight of this model, which will give us more general model. \n",
    "\n",
    "##### Model 2\n",
    "When I added the penalty to the baseline model with simply $\\lambda = 1$, the RMSE acted better on the testing set, which is about $1.23256350735$. Before applying the technique to determine optimal lamda, I just use the test data to directly find optimal lamda to compare with the cross validation result, see wether this technique is useful and efficient. The optimal lamda for test data is about $\\lambda = 1.428848$ , which result in RMSE over test set $1.23078170678$. Myself program obtain lamda is about $\\lambda = 1.63018$, which result RMSE over test set is $1.231041284233741$, which still reduced the error hugely.\n",
    "\n",
    "##### Model 3\n",
    "The RMSE over test set of neighborhood model is about $1.28697937343$, which is a little impovement. In my opnion, the data is sparse and with much noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due date**: 23:59, Nov. 18, 2016. \n",
    "Overdue submission receives no grade."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
